{
 "cells": [
  {
   "cell_type": "raw",
   "id": "08ab5fa5",
   "metadata": {},
   "source": [
    "---\n",
    "title: Demonstrate fast matrix multiplication using `pytorch` and the GPU\n",
    "author: \"John A. Marohn\"\n",
    "date: today\n",
    "abstract: For large arrays, show that GPU multiplication using `pytorch` is faster than CPU multiplication using `numpy`.  Frustratingly, the Apple Silicon GPU is limited to single precision.\n",
    "toc: true\n",
    "number-sections: true\n",
    "highlight-style: pygments\n",
    "embed-resources: true\n",
    "dpi: 300\n",
    "format:\n",
    "    html:\n",
    "        html-math-method:\n",
    "          method: mathjax\n",
    "          url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\n",
    "        code-fold: true\n",
    "        code-tools: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c0c45",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8214b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time \n",
    "from gpu1 import test0, get_device, test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790bb7c2",
   "metadata": {},
   "source": [
    "# For large arrays, GPU multiplication is faster than CPU multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6247fba",
   "metadata": {},
   "source": [
    "Print out CPU, Pytorch, and GPU information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71668b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CPU Information ---\n",
      "Processor: arm\n",
      "Physical cores: 8\n",
      "Total cores: 8\n",
      "Current CPU frequency: 4056.00 MHz\n",
      "\n",
      "--- PyTorch and GPU Information ---\n",
      "PyTorch version: 2.8.0\n",
      "It is False that CUDA is available\n",
      "It is True that MPS is available\n",
      "It is True that MPS is built\n"
     ]
    }
   ],
   "source": [
    "test0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c8e2b",
   "metadata": {},
   "source": [
    "Select the device to use for tensor computations. \\\n",
    "Try CUDA/NVIDIA, then MPS, then CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb2e6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon GPU)\n"
     ]
    }
   ],
   "source": [
    "_ = get_device(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687f1a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = [1, 10, 20, 50, 70, 100, 200, 500, 700, 1000, 2000, 5000, 7000, 8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb4c522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mps:0', '    1', '   1.915 ms', '   0.017 ms', '    0.0x', '0.0e+00', True)\n",
      "('mps:0', '   10', '   1.985 ms', '   0.038 ms', '    0.0x', '9.5e-07', True)\n",
      "('mps:0', '   20', '   1.577 ms', '   0.008 ms', '    0.0x', '0.0e+00', True)\n",
      "('mps:0', '   50', '   1.506 ms', '   0.009 ms', '    0.0x', '0.0e+00', True)\n",
      "('mps:0', '   70', '   1.431 ms', '   0.090 ms', '    0.1x', '0.0e+00', True)\n",
      "('mps:0', '  100', '   3.705 ms', '   0.081 ms', '    0.0x', '0.0e+00', True)\n",
      "('mps:0', '  200', '   3.124 ms', '   0.209 ms', '    0.1x', '0.0e+00', True)\n",
      "('mps:0', '  500', '   3.152 ms', '   1.291 ms', '    0.4x', '9.9e-05', False)\n",
      "('mps:0', '  700', '   2.427 ms', '   2.793 ms', '    1.2x', '1.4e-04', False)\n",
      "('mps:0', ' 1000', '   3.290 ms', '  10.903 ms', '    3.3x', '2.2e-04', False)\n",
      "('mps:0', ' 2000', '   3.897 ms', '  91.919 ms', '   23.6x', '4.6e-04', False)\n",
      "('mps:0', ' 5000', '   4.119 ms', ' 543.172 ms', '  131.9x', '1.3e-03', False)\n",
      "('mps:0', ' 7000', '   4.003 ms', '1426.832 ms', '  356.4x', '2.0e-03', False)\n",
      "('mps:0', ' 8000', '   4.178 ms', '2107.416 ms', '  504.4x', '2.4e-03', False)\n"
     ]
    }
   ],
   "source": [
    "for n in n_list:\n",
    "\n",
    "    (device, n, duration1, duration2, diff, same) = test1(n, verbose=False)\n",
    "    \n",
    "    print((f'{device.type}:{device.index}',\n",
    "           f'{n:5d}',\n",
    "           f'{1e3 * duration1:8.3f} ms',\n",
    "           f'{1e3 * duration2:8.3f} ms',\n",
    "           f'{duration2/duration1:7.1f}x',\n",
    "           f'{diff:0.1e}',\n",
    "           same))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281855ed",
   "metadata": {},
   "source": [
    "# Pytorch using MPS (Apple Silicon GPU) is limited to single precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f611ad",
   "metadata": {},
   "source": [
    "## Set the default torch to be single precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1ac4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd05bf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float64, torch.float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor([1.2, 3]).dtype,\n",
    " torch.tensor(np.array([1.2, 3])).dtype,\n",
    " torch.tensor(np.array([1.2, 3]).astype(np.float32)).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f1e2f",
   "metadata": {},
   "source": [
    "## Set the default torch type to be double-precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ccd3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30419bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float64, torch.float64, torch.float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor([1.2, 3]).dtype,\n",
    " torch.tensor(np.array([1.2, 3])).dtype,\n",
    " torch.tensor(np.array([1.2, 3]).astype(np.float32)).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349b28f",
   "metadata": {},
   "source": [
    "## Puzzling behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e07146",
   "metadata": {},
   "source": [
    "With the precision now set to double, `torch` appears to happily multiply double-precision arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8306a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float64, torch.float64, torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(np.array([1.2, 3]))\n",
    "b = torch.tensor(np.array([2.4, 5]))\n",
    "c = torch.matmul(a, b)\n",
    "\n",
    "(a.dtype, b.dtype, c.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f26e0b",
   "metadata": {},
   "source": [
    "But if we try to call `torch.randn` and specify double precision, we get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b07f1c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead."
     ]
    }
   ],
   "source": [
    "x = torch.randn(size=(n, n), dtype=torch.float64, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e575641",
   "metadata": {},
   "source": [
    "Use numpy to create two large double-precision arrays filled with random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c8e2563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), dtype('float64'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_np = np.random.randn(100, 100).astype(np.float64)\n",
    "b_np = np.random.randn(100, 100).astype(np.float64)\n",
    "(a_np.dtype, b_np.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f8ee3b",
   "metadata": {},
   "source": [
    "Convert these arrays to torch tensors using the `torch.tensor` function. \\\n",
    "Multiply them using `torch.matmul`. \\\n",
    "This works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52f2e08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float64, torch.float64, torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_torch = torch.tensor(a_np)\n",
    "b_torch = torch.tensor(b_np)\n",
    "c_torch = torch.matmul(a_torch, b_torch)\n",
    "(a_torch.dtype, b_torch.dtype, c_torch.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416fc96",
   "metadata": {},
   "source": [
    "If we try to convert these array stores torch tensors using the `torch.from_numpy` then we get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d50bf65d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a_torch \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_np\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead."
     ]
    }
   ],
   "source": [
    "a_torch = torch.from_numpy(a_np).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c4e6c1",
   "metadata": {},
   "source": [
    "What the heck?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ed601",
   "metadata": {},
   "source": [
    "# See also\n",
    "\n",
    "I have written stand-alone python programs to speed-test computations on the GPU using `torch`, on the GPU using `jax`, and on the CPU with parallel processing via `concurrent.futures`.\n",
    "\n",
    "    gpu1.py\n",
    "    jax1.py\n",
    "    multi1.py\n",
    "    multi2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc99a69",
   "metadata": {},
   "source": [
    "::: {.content-hidden when-format=\"html\"}\n",
    "\n",
    "# Formatting notes\n",
    "\n",
    "The header at the top of this file is for creating a nicely-formatted `.html` document using the program `quarto` ([link](https://quarto.org/)).  To create nicely-formated `.html`versions of this notebook, run `quarto` from the command line as follows\n",
    "\n",
    "    quarto render dissipation-theory--Study-66.ipynb && open dissipation-theory--Study-66.html\n",
    "    \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01680251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissipationtheory",
   "language": "python",
   "name": "dissipationtheory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
